{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "$$ #Theoretical $$"
      ],
      "metadata": {
        "id": "126j-pOw5Zak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "\n",
        "- **TensorFlow 2.0** is a major update to the TensorFlow deep learning framework that emphasizes ease of use, flexibility, and better integration with the Keras API.\n",
        "- It supports **eager execution by default**, making debugging and experimentation more intuitive.\n",
        "- TensorFlow 2.0 removes redundant APIs and simplifies model building using `tf.keras`.\n",
        "- It provides improved support for distributed training and better compatibility with Pythonic idioms.\n",
        "\n",
        "**Key Differences:**\n",
        "- **Eager Execution**: Default in 2.0 (optional in 1.x).\n",
        "- **API Cleanup**: Many deprecated APIs removed.\n",
        "- **Keras Integration**: Tight integration with `tf.keras`.\n",
        "- **Improved Performance**: Especially with GPU and TPU acceleration.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KbVVW9nl5knS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How do you install TensorFlow 2.0?\n",
        "\n",
        "- Open your terminal or command prompt.\n",
        "- Use the following pip command to install TensorFlow 2.0:\n",
        "\n",
        "  ```python\n",
        "  pip install tensorflow\n"
      ],
      "metadata": {
        "id": "mupdsNCo5kjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is the primary function of the tf.function in TensorFlow 2.0?\n",
        "\n",
        "- `tf.function` is used to **convert a Python function into a TensorFlow graph**.\n",
        "- It helps improve **performance and efficiency** by enabling TensorFlow to optimize the computation.\n",
        "\n",
        "- **Benefits:**\n",
        "  - **Faster execution** through graph optimization.\n",
        "  - Allows **autograph** conversion of Python control flow (like `if`, `for`) into TensorFlow operations.\n",
        "  - Useful for training loops and model functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "N8JrMMsj5khx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the purpose of the Model class in TensorFlow 2.0?\n",
        "\n",
        "- The `Model` class in TensorFlow 2.0 (via `tf.keras.Model`) is used to **create and manage neural network models**.\n",
        "- It provides a structure to:\n",
        "  - Define the model's **layers**.\n",
        "  - Implement the **forward pass**.\n",
        "  - Use methods like `.fit()`, `.evaluate()`, and `.predict()`.\n",
        "\n",
        "- **Usage:**\n",
        "  - You can subclass `tf.keras.Model` to build custom models.\n",
        "  - It supports **automatic training loops**, metrics, and loss computation.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "DFwlkVRK5kf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "- Use the `tf.keras` API, which provides a simple way to build models.\n",
        "- You can build models using:\n",
        "  - **Sequential API** for linear stack of layers.\n",
        "  - **Functional API** for more complex architectures.\n",
        "  - **Model subclassing** for full control and customization.\n",
        "- Define layers such as `Dense`, `Conv2D`, `Dropout`, etc.\n",
        "- Compile the model with optimizer, loss function, and metrics.\n",
        "- Train the model using `.fit()` and evaluate using `.evaluate()`.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "C-0-LKRK5kdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the importance of Tensor Space in TensorFlow?\n",
        "\n",
        "- Tensor space refers to the **multi-dimensional structure** that holds data in TensorFlow.\n",
        "- All data in TensorFlow is represented as **tensors** (scalars, vectors, matrices, and higher-order arrays).\n",
        "- It allows TensorFlow to perform **efficient mathematical operations** and parallel computation.\n",
        "- Provides a consistent way to represent inputs, outputs, and weights of neural networks.\n",
        "- Helps in **gradient computation**, transformation, and manipulation of data across layers.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eFIN_QR45kbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "\n",
        "- TensorBoard is a visualization tool used to monitor and debug machine learning models.\n",
        "- It can be integrated with TensorFlow 2.0 using built-in callbacks.\n",
        "\n",
        "**Integration Steps:**\n",
        "- Use `tf.keras.callbacks.TensorBoard` during model training.\n",
        "- Log metrics, loss, and other statistics.\n",
        "- Run TensorBoard from the terminal using the logged directory.\n",
        "\n",
        "**Benefits:**\n",
        "- Visualize training/validation loss and accuracy.\n",
        "- Inspect computation graphs and histograms.\n",
        "- Track hyperparameters and profile performance.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eQteenJB5kYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "- TensorFlow Playground is an **interactive web tool** that lets users experiment with neural networks.\n",
        "- It helps visualize how different layers, neurons, and activation functions affect learning.\n",
        "- Designed mainly for **educational purposes** to build intuition about deep learning.\n",
        "- Allows users to adjust parameters like learning rate, batch size, and input features without coding.\n",
        "- Useful for beginners to understand concepts like overfitting, underfitting, and decision boundaries.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "glEQAlvc5kQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is Netron, and how is it useful for deep learning models?\n",
        "- Netron is a tool for visualizing deep learning and machine learning models.  \n",
        "- It supports many model formats like TensorFlow, PyTorch, ONNX, Keras, etc.  \n",
        "- Helps understand model architecture by showing layers and connections visually.  \n",
        "- Useful for debugging, explaining, and sharing model structure.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "u4BsAh7F5kNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the difference between TensorFlow and PyTorch?\n",
        "- TensorFlow is developed by Google; PyTorch is developed by Facebook.  \n",
        "- TensorFlow uses static computation graphs (though TF 2.0 supports eager execution); PyTorch uses dynamic computation graphs by default.  \n",
        "- PyTorch is more Pythonic and easier for research and experimentation.  \n",
        "- TensorFlow has better deployment options for production (TensorFlow Serving, TensorFlow Lite).  \n",
        "- TensorFlow integrates tightly with Keras; PyTorch has native support for dynamic neural networks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CDn0V-385kLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. How do you install PyTorch?\n",
        "- Visit the official PyTorch website: https://pytorch.org  \n",
        "- Select your OS, package manager (pip/conda), Python version, and CUDA version.  \n",
        "- Copy the generated install command.  \n",
        "- Run the command in the terminal or Colab cell, for example:  \n",
        "  ```bash\n",
        "  !pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "a_iri2Ej5kHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the basic structure of a PyTorch neural network?\n",
        "- Create a class inheriting from `torch.nn.Module`.  \n",
        "- Initialize the network layers inside the constructor.  \n",
        "- Define the forward pass logic in the `forward` method.  \n",
        "- Use the layers to transform the input and return the output.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "i2fUPeLB5kEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What is the significance of tensors in PyTorch?\n",
        "- Tensors are the basic data structure in PyTorch, similar to arrays.  \n",
        "- They support multi-dimensional data and efficient computation on GPUs.  \n",
        "- Enable automatic differentiation for building and training neural networks.  \n",
        "- Provide interoperability with NumPy and other libraries.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Xs4xIRZP5kBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "- `torch.Tensor` stores data on the CPU by default.  \n",
        "- `torch.cuda.Tensor` stores data on the GPU for faster computation.  \n",
        "- Operations on `torch.cuda.Tensor` utilize GPU acceleration.  \n",
        "- Data needs to be explicitly moved between CPU and GPU tensors.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "03s1aIvA5j-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is the purpose of the torch.optim module in PyTorch?\n",
        "- `torch.optim` provides optimization algorithms for training models.  \n",
        "- It updates model parameters based on gradients to minimize loss.  \n",
        "- Includes optimizers like SGD, Adam, RMSprop, etc.  \n",
        "- Helps control learning rate and other optimization settings.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "V53IJ_zp5j6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What are some common activation functions used in neural networks?\n",
        "- ReLU (Rectified Linear Unit)  \n",
        "- Sigmoid  \n",
        "- Tanh (Hyperbolic Tangent)  \n",
        "- Leaky ReLU  \n",
        "- Softmax (used for multi-class classification)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oOC52l7K5j8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "- `torch.nn.Module` is the base class for all neural network models; allows custom layer definitions and complex architectures.  \n",
        "- `torch.nn.Sequential` is a container to stack layers sequentially without defining a separate class.  \n",
        "- `Sequential` is simpler but less flexible than `Module`.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ajzlk8hA5j3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. How can you monitor training progress in TensorFlow 2.0?\n",
        "- Use the `fit()` method with the `callbacks` parameter.  \n",
        "- Common callback: `tf.keras.callbacks.TensorBoard` for visualizing metrics.  \n",
        "- Use `History` object returned by `fit()` to access loss and accuracy per epoch.  \n",
        "- Print metrics after each epoch using custom callbacks or verbose settings.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DT-Ji0FF5jv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How does the Keras API fit into TensorFlow 2.0?\n",
        "- Keras is the official high-level API in TensorFlow 2.0.  \n",
        "- Simplifies building and training neural networks with easy-to-use classes.  \n",
        "- Fully integrated, allowing seamless model creation, compilation, and training.  \n",
        "- Supports both Sequential and Functional API styles.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HCi19YBo5iXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "- Image classification using Convolutional Neural Networks (CNNs).  \n",
        "- Object detection in images or videos.  \n",
        "- Natural Language Processing tasks like text classification or sentiment analysis.  \n",
        "- Time series forecasting with Recurrent Neural Networks (RNNs).  \n",
        "- Style transfer or image generation with Generative Adversarial Networks (GANs).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DoJvmFBQ8K8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "- Saves time and computational resources by reusing learned features.  \n",
        "- Requires less training data for good performance.  \n",
        "- Improves accuracy by leveraging knowledge from large datasets.  \n",
        "- Enables transfer learning for new but related tasks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PaEK7WHr8K0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ #Practical $$"
      ],
      "metadata": {
        "id": "lwW0RJBf8Kxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cqPMsKt5W8s",
        "outputId": "80b8c316-e2ae-4833-931b-bd07b50b2203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "# 1. How do you install and verify that TensorFlow 2.0 was installed successfully?\n",
        "\n",
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. How can you define a simple function in TensorFlow 2.0 to perform addition?\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add_numbers(a, b):\n",
        "    \"\"\"Simple addition function with TensorFlow optimization\"\"\"\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Test the function\n",
        "x = tf.constant([1, 2, 3])\n",
        "y = tf.constant([4, 5, 6])\n",
        "result = add_numbers(x, y)\n",
        "print(f\"Result: {result}\")  # Output: [5 7 9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVlaqAb98eLP",
        "outputId": "08f8239f-d94a-479c-a49d-8e822fc28ad3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [5 7 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "# Step 1: Prepare the Dataset\n",
        "(X_train, y_train), (X_val, y_val) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_val = X_val.astype('float32') / 255\n",
        "\n",
        "# Reshape the data\n",
        "X_train = X_train.reshape(-1, 28 * 28)\n",
        "X_val = X_val.reshape(-1, 28 * 28)\n",
        "\n",
        "# Step 2: Define the Neural Network Architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(28 * 28,)),  # Hidden layer\n",
        "    layers.Dense(10, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val))\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "results = model.evaluate(X_val, y_val)\n",
        "print('Validation loss:', results[0])\n",
        "print('Validation accuracy:', results[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPi12JG28eII",
        "outputId": "16940963-0848-4561-c713-068db808ac00"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.6286 - val_accuracy: 0.8530 - val_loss: 0.4157\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 0.3807 - val_accuracy: 0.8545 - val_loss: 0.4158\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.3379 - val_accuracy: 0.8688 - val_loss: 0.3641\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.3148 - val_accuracy: 0.8670 - val_loss: 0.3708\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2915 - val_accuracy: 0.8752 - val_loss: 0.3458\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3425\n",
            "Validation loss: 0.3457997441291809\n",
            "Validation accuracy: 0.8751999735832214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. How can you visualize the training progress using TensorFlow and Matplotlib?\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# Example dummy data: 1000 samples, 20 features each\n",
        "X_train = np.random.random((1000, 20))\n",
        "y_train = np.random.randint(2, size=(1000, 1))  # Binary labels\n",
        "\n",
        "X_val = np.random.random((200, 20))\n",
        "y_val = np.random.randint(2, size=(200, 1))\n",
        "\n",
        "# Define a simple model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(20,)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44NLeaeY8eFy",
        "outputId": "b456beb2-e0e9-4135-e547-51990df4881f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5338 - loss: 0.6954 - val_accuracy: 0.4500 - val_loss: 0.7052\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5016 - loss: 0.6897 - val_accuracy: 0.4600 - val_loss: 0.7077\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5459 - loss: 0.6893 - val_accuracy: 0.4500 - val_loss: 0.7075\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5502 - loss: 0.6879 - val_accuracy: 0.4600 - val_loss: 0.7074\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5270 - loss: 0.6841 - val_accuracy: 0.4200 - val_loss: 0.7109\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5647 - loss: 0.6834 - val_accuracy: 0.4600 - val_loss: 0.7102\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5507 - loss: 0.6819 - val_accuracy: 0.4400 - val_loss: 0.7134\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5658 - loss: 0.6835 - val_accuracy: 0.4650 - val_loss: 0.7141\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5780 - loss: 0.6775 - val_accuracy: 0.4600 - val_loss: 0.7191\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5534 - loss: 0.6831 - val_accuracy: 0.4450 - val_loss: 0.7117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. How do you install PyTorch and verify the PyTorch installation?\n",
        "\n",
        "!pip3 install torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "\n",
        "# Check if PyTorch is installed\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "# Check if CUDA is available (if you have a GPU)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
        "    print(\"Current GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcWo-v9o8eDo",
        "outputId": "ba15776b-33db-4aa2-e616-6074dccb1bc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. How do you create a simple neural network in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ========== Step 1: Generate Synthetic Data ==========\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ========== Step 2: Define Neural Network ==========\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleNN(input_size=20, hidden_size=10, output_size=2)\n",
        "\n",
        "# ========== Step 3: Training Setup ==========\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ========== Step 4: Training Loop ==========\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Mini-batch training\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print training progress\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# ========== Step 5: Evaluation ==========\n",
        "with torch.no_grad():\n",
        "    # Get predictions\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct = (predicted == y_test).sum().item()\n",
        "    total = y_test.size(0)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(\"\\nFinal Results:\")\n",
        "    print(f'Accuracy on test set: {accuracy:.2%}')\n",
        "    print(\"Sample predictions:\", predicted[:10])\n",
        "    print(\"Actual labels:\", y_test[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOAXW-qw8eBP",
        "outputId": "dbc61068-d2a6-49ab-c0a3-53cf5c0f1636"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.1816\n",
            "Epoch 20/100, Loss: 0.1581\n",
            "Epoch 30/100, Loss: 0.0973\n",
            "Epoch 40/100, Loss: 0.0976\n",
            "Epoch 50/100, Loss: 0.0885\n",
            "Epoch 60/100, Loss: 0.1090\n",
            "Epoch 70/100, Loss: 0.1027\n",
            "Epoch 80/100, Loss: 0.1131\n",
            "Epoch 90/100, Loss: 0.0728\n",
            "Epoch 100/100, Loss: 0.0545\n",
            "\n",
            "Final Results:\n",
            "Accuracy on test set: 82.00%\n",
            "Sample predictions: tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
            "Actual labels: tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. How do you define a loss function and optimizer in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ========== Step 1: Define a Simple Neural Network ==========\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 2\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# ========== Step 2: Define Loss Function ==========\n",
        "# For a classification task, we can use Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ========== Step 3: Define Optimizer ==========\n",
        "# Using Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ========== Step 4: Print Summary ==========\n",
        "print(\"Loss Function:\", criterion)\n",
        "print(\"Optimizer:\", optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTjf2pVG8d-y",
        "outputId": "bccad79b-3c76-443c-d639-8dd86a9969e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Function: CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. How do you implement a custom loss function in PyTorch?\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ========== Step 1: Define a Custom Loss Function ==========\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        return torch.mean((predictions - targets) ** 2)\n",
        "\n",
        "# ========== Step 2: Define a Simple Neural Network ==========\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ========== Step 3: Initialize Model, Loss Function, and Optimizer ==========\n",
        "input_size = 20\n",
        "hidden_size = 10\n",
        "output_size = 1  # For regression task\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Initialize custom loss function and optimizer\n",
        "loss_fn = CustomMSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ========== Step 4: Example Training Loop ==========\n",
        "# Generate some random data for demonstration\n",
        "X = torch.randn(100, input_size)  # 100 samples\n",
        "y = torch.randn(100, output_size)  # 100 target values\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Clear gradients\n",
        "    output = model(X)  # Forward pass\n",
        "    loss = loss_fn(output, y)  # Calculate loss\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQF4nvCd8d7v",
        "outputId": "2345a450-933f-485f-e4cf-9e4483d34289"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8299\n",
            "Epoch 2/10, Loss: 0.7875\n",
            "Epoch 3/10, Loss: 0.7516\n",
            "Epoch 4/10, Loss: 0.7229\n",
            "Epoch 5/10, Loss: 0.7016\n",
            "Epoch 6/10, Loss: 0.6834\n",
            "Epoch 7/10, Loss: 0.6672\n",
            "Epoch 8/10, Loss: 0.6525\n",
            "Epoch 9/10, Loss: 0.6381\n",
            "Epoch 10/10, Loss: 0.6239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. How do you save and load a TensorFlow model?\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# ========== Step 1: Create and Train a Simple Model ==========\n",
        "# Define a simple sequential model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(32,)),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Generate some random data for training\n",
        "import numpy as np\n",
        "X_train = np.random.random((1000, 32))  # 1000 samples, 32 features\n",
        "y_train = np.random.randint(10, size=(1000,))  # 1000 target values (0-9)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# ========== Step 2: Save the Model ==========\n",
        "model.save('my_model.keras')  # Save in Keras format\n",
        "\n",
        "# ========== Step 3: Load the Model ==========\n",
        "loaded_model = keras.models.load_model('my_model.keras')\n",
        "\n",
        "# ========== Step 4: Check the Loaded Model's Architecture ==========\n",
        "loaded_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "6hqx7ryD8d5T",
        "outputId": "4427c994-7d13-445f-f9f2-ddc62e70fd5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5581\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0544\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0841\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0709\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9782\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,288\u001b[0m (32.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,288</span> (32.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,762\u001b[0m (10.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,762</span> (10.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,526\u001b[0m (21.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,526</span> (21.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}